{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "546e1560",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HKEDU\\AppData\\Local\\Temp\\ipykernel_13376\\135966390.py:1: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "div.container { width:100% !important; }\n",
       "div.CodeMirror {font-family: Consolas; font-size: 25pt;}\n",
       "div.output { font-size: 20pt; font-weight: bold;}\n",
       "div.input { font-family: Consolas; font-size: 30pt;}\n",
       "div.prompt { min-width: 100px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\n",
    "\"\"\"<style>\n",
    "div.container { width:100% !important; }\n",
    "div.CodeMirror {font-family: Consolas; font-size: 25pt;}\n",
    "div.output { font-size: 20pt; font-weight: bold;}\n",
    "div.input { font-family: Consolas; font-size: 30pt;}\n",
    "div.prompt { min-width: 100px;}\n",
    "</style>\n",
    "\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dec5e3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, LeakyReLU \\\n",
    "                                                                , UpSampling2D, Conv2D\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5952d868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성자 모델을 만듭니다.\n",
    "generator = Sequential()\n",
    "generator.add(Dense(128*7*7, input_dim=100, activation=LeakyReLU(0.2)))\n",
    "generator.add(BatchNormalization())\n",
    "generator.add(Reshape((7, 7, 128)))\n",
    "generator.add(UpSampling2D())\n",
    "generator.add(Conv2D(64, kernel_size=5, padding='same'))\n",
    "generator.add(BatchNormalization())\n",
    "generator.add(Activation(LeakyReLU(0.2)))\n",
    "generator.add(UpSampling2D())\n",
    "generator.add(Conv2D(1, kernel_size=5, padding='same', activation='tanh'))\n",
    "\n",
    "# 판별자 모델을 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c9c7e6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 판별자 모델을 만듭니다.\n",
    "discriminator = Sequential()\n",
    "#strides:가로세로 크기가 더 줄어들어 새로운 특징을 뽑아 주는 효과가 생김\n",
    "#        Dropout이나 풀링처럼 새로운 필터를 적용한 효과가 생긴다.\n",
    "#        strides=2 : 2칸씩 이동  \n",
    "#        설정을 하지않으면 기본값이 1이다. \n",
    "# input_shape=(28,28,1) : 크기를 28로 맞춰준다.\n",
    "discriminator.add(Conv2D(64,kernel_size=5,strides=2,input_shape=(28,28,1),padding=\"same\"))\n",
    "discriminator.add(Activation(LeakyReLU(0.2)))\n",
    "discriminator.add(Dropout(0.3))\n",
    "discriminator.add(Conv2D(128, kernel_size=5, strides=2, padding=\"same\"))\n",
    "discriminator.add(Activation(LeakyReLU(0.2)))\n",
    "discriminator.add(Dropout(0.3))\n",
    "discriminator.add(Flatten()) # 2차원을 1차원으로 \n",
    "discriminator.add(Dense(1, activation='sigmoid'))#판별결과가 1(진짜)이나 0(가짜)이 나오면 됨\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "discriminator.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f73a65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성자와 판별자 모델을 연결시키는 gan 모델을 만듭니다.\n",
    "ginput = Input(shape=(100,))\n",
    "dis_output  = discriminator(generator(ginput))\n",
    "gan = Model(ginput, dis_output)\n",
    "gan.compile(loss=\"binary_crossentropy\", optimizer='adam')\n",
    "gan.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a7d7ff82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train, _), (_,_) = mnist.load_data()\n",
    "X_train = X_train.reshape(X_train.shape[0], 28,28,1).astype('float32')\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "19ad6560",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gan_train(epoch,batch_size, saving_interval):\n",
    "    # 테스트과정은 필요 없고 이미지만 가져오기 위해서\n",
    "    (X_train, _), (_, _) = mnist.load_data()\n",
    "    X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\n",
    "    X_train = (X_train - 127.5) / 127.5 \n",
    "    \n",
    "    true = np.ones((batch_size, 1))\n",
    "    fake = np.zeros((batch_size, 1))\n",
    "    for i in range(epoch):\n",
    "        # 실제 데이터를 판별자에 입력하는 부분입니다.\n",
    "        idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "        imgs = X_train[idx]\n",
    "        d_loss_real = discriminator.train_on_batch(imgs, true)\n",
    "\n",
    "          # 가상 이미지를 판별자에 입력하는 부분입니다.\n",
    "        noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "        gen_imgs = generator.predict(noise)\n",
    "        d_loss_fake = discriminator.train_on_batch(gen_imgs, fake)\n",
    "\n",
    "          # 판별자와 생성자의 오차를 계산합니다.\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "        g_loss = gan.train_on_batch(noise, true)\n",
    "        \n",
    "        print(f\"{i}번째 : d_loss : {d_loss} , g_loss = {g_loss}\")\n",
    "\n",
    "        if i % saving_interval == 0:\n",
    "            noise = np.random.normal(0, 1, (25, 100))\n",
    "            gen_imgs = generator.predict(noise)\n",
    "            \n",
    "            gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "            \n",
    "            ## 이미지 출력하기 위한 변수\n",
    "            fig, axs = plt.subplots(5, 5)\n",
    "            count = 0\n",
    "            for j in range(5):\n",
    "                for k in range(5):\n",
    "                    axs[j, k].imshow(gen_imgs[count, :, :, 0], cmap='gray')\n",
    "                    axs[j, k].axis('off')\n",
    "                    count += 1\n",
    "\n",
    "            fig.savefig(f\"./data/gan_mnist_{i}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355efa93",
   "metadata": {},
   "outputs": [],
   "source": [
    "gan_train(2001,32,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5089dca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers \\\n",
    "     import Input, Dense, Reshape, Flatten, Dropout,MaxPooling2D, UpSampling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "32811cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, _), (X_test, _) = mnist.load_data()\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')/255\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32')/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2271667e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성자 모델을 만듭니다.\n",
    "autoencoder = Sequential()\n",
    "\n",
    "#인코딩 부분\n",
    "autoencoder.add(Conv2D(16, kernel_size=3, padding='same', input_shape=(28,28,1), activation='relu'))\n",
    "autoencoder.add(MaxPooling2D(pool_size=2, padding='same'))\n",
    "autoencoder.add(Conv2D(8, kernel_size=3, activation='relu', padding='same'))\n",
    "autoencoder.add(MaxPooling2D(pool_size=2, padding='same'))\n",
    "autoencoder.add(Conv2D(8, kernel_size=3, strides=2, padding='same', activation='relu'))\n",
    "\n",
    "#디코딩 부분 \n",
    "#입력값에 맞게 이미미를 가져오기 위해서는 축소시킨 부분을 다시 원 크기로 만들어야 함.  \n",
    "autoencoder.add(Conv2D(8, kernel_size=3, padding='same', activation='relu'))\n",
    "autoencoder.add(UpSampling2D())\n",
    "autoencoder.add(Conv2D(8, kernel_size=3, padding='same', activation='relu'))\n",
    "autoencoder.add(UpSampling2D())\n",
    "autoencoder.add(Conv2D(16, kernel_size=3, activation='relu'))\n",
    "autoencoder.add(UpSampling2D())\n",
    "autoencoder.add(Conv2D(1, kernel_size=3, padding='same', activation='sigmoid'))\n",
    "\n",
    "# 전체 구조를 확인해 봅니다.\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e084e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컴파일 및 학습을 하는 부분입니다.\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "autoencoder.fit(X_train, X_train, epochs=50, batch_size=128, \n",
    "                validation_data=(X_test, X_test))\n",
    "\n",
    "# 학습된 결과를 출력하는 부분\n",
    "# 테스트할 이미지를 랜덤하게 불러옴.\n",
    "# 실제이미지 5개 추출\n",
    "random_test = np.random.randint(X_test.shape[0], size=5) \n",
    "# 오토인코드 모델에 넣는다.\n",
    "ae_imgs = autoencoder.predict(X_test) # autoencoder가 만든 이미지\n",
    "# 출력이미지의 크기를 정한다.\n",
    "plt.figure(figsize=(7, 2))\n",
    "\n",
    "# 랜덤으로 뽐은 이미지를 차례로 나열\n",
    "for i, image_idx in enumerate(random_test):       \n",
    "    # 테스트 이미지 출력\n",
    "    ax = plt.subplot(2, 7, i + 1) \n",
    "    plt.imshow(X_test[image_idx].reshape(28, 28))   \n",
    "    ax.axis('off')\n",
    "    # 오토 인코딩 결과를 출력\n",
    "    ax = plt.subplot(2, 7, 7 + i +1)\n",
    "    plt.imshow(ae_imgs[image_idx].reshape(28, 28)) \n",
    "    ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a16b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#학습셋의 변형을 설정하는 부분입니다. \n",
    "train_datagen = ImageDataGenerator(rescale=1./255,          \n",
    "                                  horizontal_flip=True,    \n",
    "                                  width_shift_range=0.1,    \n",
    "                                  height_shift_range=0.1,   \n",
    "                                  rotation_range=5,        \n",
    "                                  shear_range=0.7,         \n",
    "                                  zoom_range=1.2,          \n",
    "                                  vertical_flip=True,      \n",
    "                                  fill_mode='nearest'      \n",
    "                                  )      \n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "       './data',   # 학습셋이 있는 폴더의 위치입니다.\n",
    "       target_size=(150, 150),\n",
    "       batch_size=5,\n",
    "       class_mode='binary')\n",
    "\n",
    "# 테스트셋은 이미지 부풀리기 과정을 진행하지 않습니다.\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)  \n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "       './data',   # 테스트셋이 있는 폴더의 위치입니다.\n",
    "       target_size=(150, 150),\n",
    "       batch_size=5,\n",
    "       class_mode='binary')\n",
    "\n",
    "\n",
    "# 앞서 배운 CNN 모델을 만들어 적용해 보겠습니다.\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(150,150,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5ceba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install SciPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fa178c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 실행의 옵션을 설정합니다. \n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizers.Adam(learning_rate=0.0002), metrics=['accuracy'])\n",
    "\n",
    "# 학습의 조기 중단을 설정합니다.\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "#모델을 실행합니다\n",
    "history = model.fit(\n",
    "       train_generator,\n",
    "       epochs=100,\n",
    "       validation_data=test_generator,\n",
    "       validation_steps=10, \n",
    "       callbacks=[early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc315c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import Input, models, layers, optimizers, metrics\n",
    "from tensorflow.keras.layers import Dense, Flatten, Activation, Dropout\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 학습셋의 변형을 설정하는 부분입니다. \n",
    "train_datagen = ImageDataGenerator(rescale=1./255,          \n",
    "                                  horizontal_flip=True,    \n",
    "                                  width_shift_range=0.1,   \n",
    "                                  height_shift_range=0.1,   \n",
    "                                  rotation_range=5,        \n",
    "                                  shear_range=0.7,         \n",
    "                                  zoom_range=1.2,          \n",
    "                                  vertical_flip=True,      \n",
    "                                  fill_mode='nearest'      \n",
    "                                  )      \n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "       './data/train',\n",
    "       target_size=(150, 150),\n",
    "       batch_size=5,\n",
    "       class_mode='binary')\n",
    "\n",
    "# 테스트셋의 정규화를 설정합니다.\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "       './data/test',\n",
    "       target_size=(150, 150),\n",
    "       batch_size=5,\n",
    "       class_mode='binary')\n",
    "\n",
    "# VGG16 모델을 불러옵니다.\n",
    "transfer_model = VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
    "transfer_model.trainable = False\n",
    "transfer_model.summary()\n",
    "\n",
    "# 우리의 모델을 설정합니다.\n",
    "finetune_model = models.Sequential()\n",
    "finetune_model.add(transfer_model)\n",
    "finetune_model.add(Flatten())\n",
    "finetune_model.add(Dense(64))\n",
    "finetune_model.add(Activation('relu'))\n",
    "finetune_model.add(Dropout(0.5))\n",
    "finetune_model.add(Dense(1))\n",
    "finetune_model.add(Activation('sigmoid'))\n",
    "finetune_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f32f14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델의 실행 옵션을 설정합니다. \n",
    "finetune_model.compile(loss='binary_crossentropy', optimizer=optimizers.Adam(learning_rate=0.0002), metrics=['accuracy'])\n",
    "\n",
    "# 학습의 조기 중단을 설정합니다.\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "# 모델을 실행합니다.\n",
    "history = finetune_model.fit(\n",
    "       train_generator,\n",
    "       epochs=20,\n",
    "       validation_data=test_generator,\n",
    "       validation_steps=10, \n",
    "       callbacks=[early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f56761",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74fa8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tf-explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac796e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52955ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.applications import VGG16\n",
    "\n",
    "\n",
    "from tf_explain.core.grad_cam import GradCAM\n",
    "from tf_explain.core.occlusion_sensitivity import OcclusionSensitivity\n",
    "\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "\n",
    "images_originals = []\n",
    "\n",
    "\n",
    "for img_path in glob.glob('./data/img/*_0.jpg'):\n",
    "    images_originals.append(mpimg.imread(img_path))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "\n",
    "\n",
    "for i, image_o in enumerate(images_originals):\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "    plt.imshow(image_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9131e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = VGG16(weights=\"imagenet\", include_top=True)\n",
    "\n",
    "\n",
    "input_list = [\"maltese\", \"persian_cat\", \"squirrel_monkey\", \"grand_piano\", \"yawl\"]\n",
    "imagenet_index = [\"153\", \"283\", \"382\", \"579\", \"914\"]\n",
    "\n",
    "\n",
    "explainer = GradCAM()\n",
    "\n",
    "\n",
    "images_cams = []\n",
    "\n",
    "\n",
    "for l, i in zip(input_list, imagenet_index):  \n",
    "    img = load_img('./data/img/{}_0.jpg'.format(l), target_size=(224, 224)) \n",
    "    img = img_to_array(img) \n",
    "    data = ([img], None)\n",
    "    grid = explainer.explain(data, model, int(i))                 \n",
    "    explainer.save(grid, \".\", './data/img/{}_cam.jpg'.format(l)) \n",
    "\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "\n",
    "for img_path in glob.glob('./data/img/*_cam.jpg'):\n",
    "    images_cams.append(mpimg.imread(img_path))\n",
    "\n",
    "for i, image_c in enumerate(images_cams):\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "    plt.imshow(image_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bef9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오클루전 알고리즘을 불러와 실행합니다.\n",
    "\n",
    "explainer = OcclusionSensitivity()\n",
    "\n",
    "# 알고리즘이 적용된 이미지가 들어갈 빈 리스트 만들기\n",
    "images_occ1s = []\n",
    "\n",
    "# 패치 사이즈를 정합니다. \n",
    "patch_size = 40\n",
    "\n",
    "# 오클루전 알고리즘 실행\n",
    "for l, i in zip(input_list, imagenet_index):\n",
    "    img = load_img('./data/img/{}_0.jpg'.format(l), target_size=(224, 224))\n",
    "    img = img_to_array(img)\n",
    "    data = ([img], None)\n",
    "    grid = explainer.explain(data, model, int(i), patch_size) #패치 사이즈의 설정이 추가됩니다. \n",
    "    explainer.save(grid, \".\", './data/img/{}_occ1.jpg'.format(l))\n",
    "\n",
    "# 오클루전 알고리즘이 적용된 이미지를 불러오는 부분의 시작입니다.\n",
    "plt.figure(figsize=(20,20))\n",
    "\n",
    "for img_path in glob.glob('./data/img/*_occ1.jpg'):\n",
    "    images_occ1s.append(mpimg.imread(img_path))\n",
    "\n",
    "for i, image in enumerate(images_occ1s):\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "    plt.imshow(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cc082a",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = 20\n",
    "\n",
    "images_occ2s = []\n",
    "\n",
    "for l, i in zip(input_list, imagenet_index):\n",
    "    img = load_img('./data/img/{}_0.jpg'.format(l), target_size=(224, 224))\n",
    "    img = img_to_array(img)\n",
    "    data = ([img], None)\n",
    "    grid = explainer.explain(data, model, int(i), patch_size) \n",
    "    explainer.save(grid, \".\", './data/img/{}_occ2.jpg'.format(l))\n",
    "\n",
    "for img_path in glob.glob('./data/img/*_occ2.jpg'):\n",
    "    images_occ2s.append(mpimg.imread(img_path))\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "for i, image in enumerate(images_occ2s):\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9d91e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 이미지 한 눈에 보기.\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "\n",
    "images = []\n",
    "for img_path in glob.glob('./data/img/*.jpg'):\n",
    "    images.append(mpimg.imread(img_path))\n",
    "\n",
    "for i, image in enumerate(images):\n",
    "    plt.subplot(5, 4, i + 1)\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ee8c1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
